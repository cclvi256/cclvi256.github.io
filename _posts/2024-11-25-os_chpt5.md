---
title: "OS: Note of Chapter 5"
date: 2024-11-25 20:00:00 +0800
categories:
  - Computer Science
  - Operating System
tags:
  - Operating System
  - Concurrency
math: true
---

## Concurrency Problems with Out-of-Order Execution

Concurrency is nowadays one of the most difficult aspects of system programming. The ad hoc techniques are vulnerable to subtle programming errors whose effects are difficult to reproduce and diagnose. Summarily errors about concurrency occurs at a very low probability, leading to difficulty of reproducing and debugging.

## Concurrency

The **_central themes_** of OS design are all concerned with the management of processes and threads. Concurrency is not the same as **_parallelism_**. Concurrency focuses on simutaneously execution during a **_period_**, and parallelism focuses on simutaneously execution during a **_time point_**. In summary, concurrency is a **_logical_** concept, and parallelism is a **_physical_** concept.

The basic principle of concurrency is interleaving and overlapping of processes.

> This chapter is focusing on uniprocessor concurrency.

For uniprocessor concurrency, the relative speed of execution of processes **_cannot be predicted_**. It depends on activities of other processes, the way that the OS handles interrupts, and the scheduling policies of the OS.

Example:

```
void echo() {
  chin = getchar();
  chout = chin;
  putchar(chout);
}
```

Suppose that there're 2 same processes with the same code above. The execution of the 2 processes may have passing unexpected results: the process 1 gives the value that process 2 inputs, etc.

This problem is caused by **_shared R/W memory access_**. The 2 processes both have the read and write access to a same memory address. The uncertainty of the interrupt makes the shared memory access unpredictable, and because of the code is too short, so in almost many circumstences there will not be any error. This causes that troubles about concurrency are difficult to reproduce and debug. The solution of this problem is using **_mutual exclusion_**.

Concurrency problems raises many issues, for which the OS must be able to:

- keep track of various processes
- allocate and deallocate resources for each active process, such as processor time, memory, files, and I/O devices
- protect the data and physical resources of each process **_against interference_** by other processes
- ensure that the processes and outputs are **_independent_** of the processing speed

## Process Interaction

The processes can be unaware, indirectly aware, or directly aware the existence of another process, and the interaction between processes can be **_cooperative_** or **_competitive_**.

| Degree of awareness |               Interaction                |
| :-----------------: | :--------------------------------------: |
|       Unaware       |         Independent, competitive         |
|  Indirectly aware   | Independent, cooperative by sharing data |
|   Directly aware    |       Cooperative by communication       |

## Mutual Exclusion

The implement of mutual exclusion is like `entercritical()` and `exitcritical()`, such as:

```
entercritical (Ra);
// critical section
exitcritical (Ra);
```

This is more similar to the `cli` and `sti`, which may lead to ***unbreakable infinite loop***, and fall back to single process if there's many `cli` and `sti` in the code.

## Semaphore

Semaphore can be initialesed to a nonnegative integer value. The semaphore can be incremented or decremented by one. The semaphore primitives is defined as:

```c
struct semaphore {
  int count;
  queueType queue;
};

void semWait(semaphore s) {
  --s.count;
  if (s.count < 0) {
    // add this process to s.queue
    // block this process
  }
}

void semSignal(semaphore s) {
  ++s.count;
  if (s.count <= 0) {
    // remove a process P from s.queue
    // wakeup P
  }
}
```

There's also a ***binary semaphore***, which is a semaphore that can only have the values 0 and 1. The definition is like:

```c

```

Then we can use semaphore to protect data, when a process want to enter critical section, it calls `semWait(lock)`, then `lock.count` become 0, and the process is pushed back into the queue.

Suppose when the 1st process is occupying the critical section, the 2nd and 3rd processes comes. Then the `lock.count` become -1 and -2 respectively. When the 1st process leaves the critical section, the `lock.count` become -1, and the 2nd process is waken up and enters the critical section. When the 2nd process leaves the critical section, the `lock.count` become 0, and the 3rd process is waken up and enters the critical section.

In this example, the 1st process entered the critical section when semaphore is positive, but the 2nd and 3rd processes entered the critical section when semaphore is nonpositive, this is because the 2nd and 3rd processes are already in the queue, like using a ***booked ticket***.